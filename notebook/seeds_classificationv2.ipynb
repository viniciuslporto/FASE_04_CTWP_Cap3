# Classifica√ß√£o de Variedades de Gr√£os de Trigo
## Aplica√ß√£o da Metodologia CRISP-DM

**Integrantes do Grupo:**
- Vinicius de Santana Gama - RM566672
- Pedro Carvalho Rocha Lima - RM567330
- Vinicius Lisboa Porto - RM561406
- Marlon Paulino Marinho - RM566793
- Danilo Marques Dantas - RM567583

---

## Contexto do Problema

Em cooperativas agr√≠colas de pequeno porte, a classifica√ß√£o manual de gr√£os √© demorada e sujeita a erros humanos. Este projeto desenvolve um modelo de aprendizado de m√°quina para automatizar a classifica√ß√£o de tr√™s variedades de trigo (Kama, Rosa e Canadian) com base em caracter√≠sticas f√≠sicas dos gr√£os.

**Objetivo:** Aplicar CRISP-DM para desenvolver, comparar e otimizar modelos de classifica√ß√£o que auxiliem cooperativas agr√≠colas na automa√ß√£o do processo de classifica√ß√£o de gr√£os.
## üìÅ IMPORTANTE: Upload do Dataset

**ANTES DE CONTINUAR:**
1. Clique no √≠cone de **pasta** üìÅ no menu lateral esquerdo
2. Clique no √≠cone de **upload** (seta para cima)
3. Selecione o arquivo `seeds_dataset.txt`
4. Aguarde o upload completar
5. Execute as c√©lulas abaixo
## 1. Importa√ß√£o de Bibliotecas
# Manipula√ß√£o de dados
import pandas as pd
import numpy as np
import os

# Visualiza√ß√£o
import matplotlib.pyplot as plt
import seaborn as sns

# Pr√©-processamento
from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score
from sklearn.preprocessing import StandardScaler

# Algoritmos de classifica√ß√£o
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.linear_model import LogisticRegression

# M√©tricas de avalia√ß√£o
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    confusion_matrix, classification_report, ConfusionMatrixDisplay
)

# Configura√ß√µes de visualiza√ß√£o
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette('husl')
plt.rcParams['figure.figsize'] = (12, 6)
plt.rcParams['font.size'] = 10

# Ignorar warnings desnecess√°rios
import warnings
warnings.filterwarnings('ignore')

print("‚úì Bibliotecas importadas com sucesso")
## 2. Carregamento e Explora√ß√£o Inicial dos Dados
# Defini√ß√£o dos nomes das colunas conforme documenta√ß√£o
column_names = [
    'Area',
    'Perimetro',
    'Compacidade',
    'Comprimento_Nucleo',
    'Largura_Nucleo',
    'Coef_Assimetria',
    'Comprimento_Sulco',
    'Variedade'
]

# Buscar arquivo em poss√≠veis localiza√ß√µes
possible_paths = [
    'seeds_dataset.txt',  # Diret√≥rio atual
    '/content/seeds_dataset.txt',  # Raiz do Colab
    'sample_data/seeds_dataset.txt'  # Pasta sample_data
]

file_path = None
for path in possible_paths:
    if os.path.exists(path):
        file_path = path
        print(f"‚úì Arquivo encontrado em: {path}")
        break

if file_path is None:
    print("‚ùå ERRO: Arquivo seeds_dataset.txt n√£o encontrado!")
    print("\nüìã INSTRU√á√ïES:")
    print("1. Clique no √≠cone de PASTA üìÅ no menu lateral esquerdo")
    print("2. Clique no √≠cone de UPLOAD (seta para cima)")
    print("3. Selecione o arquivo 'seeds_dataset.txt'")
    print("4. Aguarde o upload completar")
    print("5. Execute esta c√©lula novamente")
    raise FileNotFoundError("seeds_dataset.txt n√£o encontrado")

# Carregamento do dataset
# Usando delimitador de espa√ßos em branco (tabs ou espa√ßos m√∫ltiplos)
df = pd.read_csv(
    file_path,
    sep='\s+',  # Aceita um ou mais espa√ßos/tabs
    names=column_names,
    header=None,
    engine='python'  # Necess√°rio para usar regex no sep
)

print(f"\n‚úì Dataset carregado com sucesso!")
print(f"Dimens√µes: {df.shape[0]} amostras x {df.shape[1]} colunas")
print(f"\n{'='*60}")
print("PRIMEIRAS LINHAS DO DATASET")
print(f"{'='*60}")
df.head(10)
# Informa√ß√µes gerais do dataset
print("INFORMA√á√ïES GERAIS DO DATASET")
print(f"{'='*60}")
df.info()

print(f"\n{'='*60}")
print("DISTRIBUI√á√ÉO DAS CLASSES")
print(f"{'='*60}")
print(df['Variedade'].value_counts().sort_index())
print(f"\nClasses balanceadas: {df['Variedade'].value_counts().std() < 5}")
# Mapeamento das variedades
variedades_map = {1: 'Kama', 2: 'Rosa', 3: 'Canadian'}
print("\nMapeamento das Variedades:")
for key, value in variedades_map.items():
    count = (df['Variedade'] == key).sum()
    print(f"  {key} = {value} ({count} amostras)")
## 3. An√°lise Explorat√≥ria de Dados (EDA)

### 3.1 Estat√≠sticas Descritivas
# Estat√≠sticas descritivas completas
print("ESTAT√çSTICAS DESCRITIVAS")
print(f"{'='*60}")
df.describe().T
# Verifica√ß√£o de valores ausentes
print("VERIFICA√á√ÉO DE VALORES AUSENTES")
print(f"{'='*60}")
missing = df.isnull().sum()
print(missing)
print(f"\n‚úì Total de valores ausentes: {missing.sum()}")
### 3.2 Visualiza√ß√£o da Distribui√ß√£o das Features
# Histogramas das features
features = df.columns[:-1]

fig, axes = plt.subplots(3, 3, figsize=(16, 12))
axes = axes.ravel()

for idx, col in enumerate(features):
    axes[idx].hist(df[col], bins=25, edgecolor='black', alpha=0.7)
    axes[idx].set_title(f'Distribui√ß√£o: {col}', fontweight='bold')
    axes[idx].set_xlabel(col)
    axes[idx].set_ylabel('Frequ√™ncia')
    axes[idx].grid(True, alpha=0.3)

# Remover subplots vazios
fig.delaxes(axes[7])
fig.delaxes(axes[8])

plt.tight_layout()
plt.suptitle('Distribui√ß√£o das Caracter√≠sticas dos Gr√£os', fontsize=16, fontweight='bold', y=1.01)
plt.show()
### 3.3 An√°lise de Outliers com Boxplots
# Boxplots para identificar outliers
fig, axes = plt.subplots(3, 3, figsize=(16, 12))
axes = axes.ravel()

for idx, col in enumerate(features):
    axes[idx].boxplot(df[col], vert=True, patch_artist=True,
                     boxprops=dict(facecolor='lightblue', alpha=0.7),
                     medianprops=dict(color='red', linewidth=2))
    axes[idx].set_title(f'Boxplot: {col}', fontweight='bold')
    axes[idx].set_ylabel(col)
    axes[idx].grid(True, alpha=0.3)

fig.delaxes(axes[7])
fig.delaxes(axes[8])

plt.tight_layout()
plt.suptitle('An√°lise de Outliers - Boxplots', fontsize=16, fontweight='bold', y=1.01)
plt.show()
### 3.4 Matriz de Correla√ß√£o
# Matriz de correla√ß√£o
correlation_matrix = df[features].corr()

plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm',
            square=True, linewidths=0.5, cbar_kws={'shrink': 0.8})
plt.title('Matriz de Correla√ß√£o entre Features', fontsize=14, fontweight='bold', pad=20)
plt.tight_layout()
plt.show()

# Identificar correla√ß√µes fortes
print("\nCORRELA√á√ïES FORTES (|r| > 0.8):")
print(f"{'='*60}")
for i in range(len(correlation_matrix.columns)):
    for j in range(i+1, len(correlation_matrix.columns)):
        if abs(correlation_matrix.iloc[i, j]) > 0.8:
            print(f"{correlation_matrix.columns[i]:25} <-> {correlation_matrix.columns[j]:25} = {correlation_matrix.iloc[i, j]:.3f}")
### 3.5 Scatter Plots - Rela√ß√µes entre Features
# Scatter plots das principais rela√ß√µes
principais_relacoes = [
    ('Area', 'Perimetro'),
    ('Comprimento_Nucleo', 'Largura_Nucleo'),
    ('Area', 'Compacidade'),
    ('Perimetro', 'Comprimento_Sulco')
]

fig, axes = plt.subplots(2, 2, figsize=(14, 10))
axes = axes.ravel()

cores = {1: 'red', 2: 'blue', 3: 'green'}
labels = {1: 'Kama', 2: 'Rosa', 3: 'Canadian'}

for idx, (feat1, feat2) in enumerate(principais_relacoes):
    for variedade in [1, 2, 3]:
        mask = df['Variedade'] == variedade
        axes[idx].scatter(df[mask][feat1], df[mask][feat2],
                         c=cores[variedade], label=labels[variedade],
                         alpha=0.6, edgecolors='black', linewidth=0.5)
    
    axes[idx].set_xlabel(feat1, fontweight='bold')
    axes[idx].set_ylabel(feat2, fontweight='bold')
    axes[idx].set_title(f'{feat1} vs {feat2}', fontweight='bold')
    axes[idx].legend()
    axes[idx].grid(True, alpha=0.3)

plt.tight_layout()
plt.suptitle('Rela√ß√µes entre Features por Variedade', fontsize=16, fontweight='bold', y=1.01)
plt.show()
### 3.6 Distribui√ß√£o de Features por Variedade
# Boxplots por variedade
fig, axes = plt.subplots(3, 3, figsize=(16, 12))
axes = axes.ravel()

for idx, col in enumerate(features):
    data_by_variety = [df[df['Variedade'] == v][col].values for v in [1, 2, 3]]
    
    bp = axes[idx].boxplot(data_by_variety, labels=['Kama', 'Rosa', 'Canadian'],
                           patch_artist=True)
    
    for patch, color in zip(bp['boxes'], ['red', 'blue', 'green']):
        patch.set_facecolor(color)
        patch.set_alpha(0.6)
    
    axes[idx].set_title(f'{col} por Variedade', fontweight='bold')
    axes[idx].set_ylabel(col)
    axes[idx].grid(True, alpha=0.3)

fig.delaxes(axes[7])
fig.delaxes(axes[8])

plt.tight_layout()
plt.suptitle('Distribui√ß√£o das Features por Variedade de Trigo', fontsize=16, fontweight='bold', y=1.01)
plt.show()
## 4. Pr√©-processamento dos Dados

### 4.1 Separa√ß√£o de Features e Target
# Separa√ß√£o de features (X) e target (y)
X = df.drop('Variedade', axis=1)
y = df['Variedade']

print(f"Features (X): {X.shape}")
print(f"Target (y): {y.shape}")
print(f"\nDistribui√ß√£o do target:")
print(y.value_counts().sort_index())
### 4.2 Divis√£o em Conjuntos de Treino e Teste
# Divis√£o estratificada 70/30
X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.3,
    random_state=42,
    stratify=y
)

print(f"Conjunto de Treino: {X_train.shape[0]} amostras")
print(f"Conjunto de Teste: {X_test.shape[0]} amostras")
print(f"\nDistribui√ß√£o no Treino:")
print(y_train.value_counts().sort_index())
print(f"\nDistribui√ß√£o no Teste:")
print(y_test.value_counts().sort_index())
### 4.3 Padroniza√ß√£o das Features
# Padroniza√ß√£o usando StandardScaler
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Converter de volta para DataFrame para facilitar an√°lise
X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X.columns)
X_test_scaled_df = pd.DataFrame(X_test_scaled, columns=X.columns)

print("‚úì Dados padronizados com sucesso")
print(f"\nEstat√≠sticas ap√≥s padroniza√ß√£o (Treino):")
print(X_train_scaled_df.describe().loc[['mean', 'std']].T)
## 5. Implementa√ß√£o dos Modelos de Classifica√ß√£o

### 5.1 Defini√ß√£o dos Modelos Base
# Dicion√°rio de modelos base
models = {
    'KNN': KNeighborsClassifier(),
    'SVM': SVC(random_state=42),
    'Random Forest': RandomForestClassifier(random_state=42),
    'Naive Bayes': GaussianNB(),
    'Logistic Regression': LogisticRegression(random_state=42, max_iter=1000)
}

print("MODELOS DEFINIDOS:")
print(f"{'='*60}")
for name in models.keys():
    print(f"  ‚Ä¢ {name}")
### 5.2 Treinamento e Avalia√ß√£o dos Modelos Base
# Treinamento e avalia√ß√£o
results = {}

print("TREINAMENTO DOS MODELOS BASE")
print(f"{'='*60}\n")

for name, model in models.items():
    print(f"Treinando {name}...")
    
    # Treinar
    model.fit(X_train_scaled, y_train)
    
    # Predi√ß√µes
    y_pred = model.predict(X_test_scaled)
    
    # M√©tricas
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred, average='weighted')
    recall = recall_score(y_test, y_pred, average='weighted')
    f1 = f1_score(y_test, y_pred, average='weighted')
    
    # Valida√ß√£o cruzada
    cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5)
    
    # Armazenar resultados
    results[name] = {
        'model': model,
        'y_pred': y_pred,
        'accuracy': accuracy,
        'precision': precision,
        'recall': recall,
        'f1_score': f1,
        'cv_mean': cv_scores.mean(),
        'cv_std': cv_scores.std()
    }
    
    print(f"  ‚úì Acur√°cia: {accuracy:.4f}")
    print(f"  ‚úì CV Score: {cv_scores.mean():.4f} (¬±{cv_scores.std():.4f})")
    print()

print("‚úì Todos os modelos treinados com sucesso")
### 5.3 Compara√ß√£o de Desempenho dos Modelos Base
# Criar DataFrame com m√©tricas
metrics_df = pd.DataFrame({
    'Modelo': list(results.keys()),
    'Acur√°cia': [results[m]['accuracy'] for m in results],
    'Precis√£o': [results[m]['precision'] for m in results],
    'Recall': [results[m]['recall'] for m in results],
    'F1-Score': [results[m]['f1_score'] for m in results],
    'CV Mean': [results[m]['cv_mean'] for m in results],
    'CV Std': [results[m]['cv_std'] for m in results]
})

metrics_df = metrics_df.sort_values('Acur√°cia', ascending=False).reset_index(drop=True)

print("COMPARA√á√ÉO DE DESEMPENHO - MODELOS BASE")
print(f"{'='*80}")
print(metrics_df.to_string(index=False))
print(f"{'='*80}")
# Visualiza√ß√£o comparativa
fig, axes = plt.subplots(1, 2, figsize=(16, 6))

# Gr√°fico 1: Todas as m√©tricas
metrics_plot = metrics_df.set_index('Modelo')[['Acur√°cia', 'Precis√£o', 'Recall', 'F1-Score']]
metrics_plot.plot(kind='bar', ax=axes[0], width=0.8)
axes[0].set_title('Compara√ß√£o de M√©tricas - Modelos Base', fontweight='bold', fontsize=12)
axes[0].set_ylabel('Score')
axes[0].set_xlabel('Modelo')
axes[0].legend(loc='lower right')
axes[0].set_ylim([0.85, 1.0])
axes[0].grid(True, alpha=0.3)
axes[0].tick_params(axis='x', rotation=45)

# Gr√°fico 2: Valida√ß√£o Cruzada
x_pos = np.arange(len(metrics_df))
axes[1].bar(x_pos, metrics_df['CV Mean'], yerr=metrics_df['CV Std'],
           capsize=5, alpha=0.7, color='skyblue', edgecolor='black')
axes[1].set_xticks(x_pos)
axes[1].set_xticklabels(metrics_df['Modelo'], rotation=45, ha='right')
axes[1].set_title('Valida√ß√£o Cruzada (5-Fold)', fontweight='bold', fontsize=12)
axes[1].set_ylabel('Acur√°cia M√©dia')
axes[1].set_xlabel('Modelo')
axes[1].set_ylim([0.85, 1.0])
axes[1].grid(True, alpha=0.3)

plt.tight_layout()
plt.show()
### 5.4 Matrizes de Confus√£o dos Modelos Base
# Plotar matrizes de confus√£o
fig, axes = plt.subplots(2, 3, figsize=(16, 10))
axes = axes.ravel()

for idx, (name, result) in enumerate(results.items()):
    cm = confusion_matrix(y_test, result['y_pred'])
    
    disp = ConfusionMatrixDisplay(
        confusion_matrix=cm,
        display_labels=['Kama', 'Rosa', 'Canadian']
    )
    
    disp.plot(ax=axes[idx], cmap='Blues', colorbar=False)
    axes[idx].set_title(f'{name}\nAcur√°cia: {result["accuracy"]:.4f}',
                       fontweight='bold', fontsize=11)
    axes[idx].grid(False)

# Remover subplot vazio
fig.delaxes(axes[5])

plt.tight_layout()
plt.suptitle('Matrizes de Confus√£o - Modelos Base', fontsize=16, fontweight='bold', y=1.01)
plt.show()
### 5.5 Relat√≥rios de Classifica√ß√£o Detalhados
# Relat√≥rios detalhados por classe
print("RELAT√ìRIOS DE CLASSIFICA√á√ÉO DETALHADOS")
print(f"{'='*80}\n")

target_names = ['Kama', 'Rosa', 'Canadian']

for name, result in results.items():
    print(f"\n{name}")
    print("-" * 60)
    print(classification_report(y_test, result['y_pred'],
                               target_names=target_names,
                               digits=4))
## 6. Otimiza√ß√£o de Hiperpar√¢metros

### 6.1 Defini√ß√£o dos Grids de Hiperpar√¢metros
# Grids de hiperpar√¢metros para otimiza√ß√£o
param_grids = {
    'KNN': {
        'n_neighbors': [3, 5, 7, 9, 11],
        'weights': ['uniform', 'distance'],
        'metric': ['euclidean', 'manhattan']
    },
    'SVM': {
        'C': [0.1, 1, 10, 100],
        'kernel': ['linear', 'rbf', 'poly'],
        'gamma': ['scale', 'auto']
    },
    'Random Forest': {
        'n_estimators': [50, 100, 200],
        'max_depth': [None, 10, 20, 30],
        'min_samples_split': [2, 5, 10],
        'min_samples_leaf': [1, 2, 4]
    },
    'Logistic Regression': {
        'C': [0.01, 0.1, 1, 10, 100],
        'solver': ['lbfgs', 'liblinear'],
        'penalty': ['l2']
    }
}

print("GRIDS DE HIPERPAR√ÇMETROS DEFINIDOS")
print(f"{'='*60}\n")
for model_name, params in param_grids.items():
    print(f"{model_name}:")
    for param, values in params.items():
        print(f"  ‚Ä¢ {param}: {values}")
    print()
### 6.2 Execu√ß√£o do GridSearchCV
# GridSearch para otimiza√ß√£o
optimized_results = {}

print("OTIMIZA√á√ÉO DE HIPERPAR√ÇMETROS (GridSearchCV)")
print(f"{'='*60}\n")

for name in param_grids.keys():
    print(f"Otimizando {name}...")
    
    # Criar novo modelo
    if name == 'KNN':
        base_model = KNeighborsClassifier()
    elif name == 'SVM':
        base_model = SVC(random_state=42)
    elif name == 'Random Forest':
        base_model = RandomForestClassifier(random_state=42)
    elif name == 'Logistic Regression':
        base_model = LogisticRegression(random_state=42, max_iter=1000)
    
    # GridSearch
    grid_search = GridSearchCV(
        base_model,
        param_grids[name],
        cv=5,
        scoring='accuracy',
        n_jobs=-1,
        verbose=0
    )
    
    grid_search.fit(X_train_scaled, y_train)
    
    # Melhor modelo
    best_model = grid_search.best_estimator_
    y_pred_opt = best_model.predict(X_test_scaled)
    
    # M√©tricas
    accuracy_opt = accuracy_score(y_test, y_pred_opt)
    precision_opt = precision_score(y_test, y_pred_opt, average='weighted')
    recall_opt = recall_score(y_test, y_pred_opt, average='weighted')
    f1_opt = f1_score(y_test, y_pred_opt, average='weighted')
    
    # Armazenar
    optimized_results[name] = {
        'model': best_model,
        'y_pred': y_pred_opt,
        'accuracy': accuracy_opt,
        'precision': precision_opt,
        'recall': recall_opt,
        'f1_score': f1_opt,
        'best_params': grid_search.best_params_,
        'cv_score': grid_search.best_score_,
        'improvement': accuracy_opt - results[name]['accuracy']
    }
    
    print(f"  ‚úì Melhor Score CV: {grid_search.best_score_:.4f}")
    print(f"  ‚úì Acur√°cia Teste: {accuracy_opt:.4f}")
    print(f"  ‚úì Melhoria: {optimized_results[name]['improvement']:+.4f}")
    print(f"  ‚úì Melhores Par√¢metros: {grid_search.best_params_}")
    print()

# Naive Bayes n√£o precisa otimiza√ß√£o (sem hiperpar√¢metros relevantes)
optimized_results['Naive Bayes'] = results['Naive Bayes'].copy()
optimized_results['Naive Bayes']['best_params'] = 'N/A'
optimized_results['Naive Bayes']['improvement'] = 0.0

print("‚úì Otimiza√ß√£o conclu√≠da")
### 6.3 Compara√ß√£o: Modelos Base vs Otimizados
# Criar DataFrame comparativo
comparison_df = pd.DataFrame({
    'Modelo': list(optimized_results.keys()),
    'Acur√°cia Base': [results[m]['accuracy'] for m in optimized_results],
    'Acur√°cia Otimizada': [optimized_results[m]['accuracy'] for m in optimized_results],
    'Melhoria': [optimized_results[m]['improvement'] for m in optimized_results],
    'F1-Score Otimizado': [optimized_results[m]['f1_score'] for m in optimized_results]
})

comparison_df = comparison_df.sort_values('Acur√°cia Otimizada', ascending=False).reset_index(drop=True)

print("COMPARA√á√ÉO: MODELOS BASE vs OTIMIZADOS")
print(f"{'='*80}")
print(comparison_df.to_string(index=False))
print(f"{'='*80}")
# Visualiza√ß√£o da compara√ß√£o
fig, ax = plt.subplots(figsize=(12, 6))

x = np.arange(len(comparison_df))
width = 0.35

bars1 = ax.bar(x - width/2, comparison_df['Acur√°cia Base'],
               width, label='Base', alpha=0.8, color='lightcoral')
bars2 = ax.bar(x + width/2, comparison_df['Acur√°cia Otimizada'],
               width, label='Otimizado', alpha=0.8, color='lightgreen')

ax.set_xlabel('Modelo', fontweight='bold')
ax.set_ylabel('Acur√°cia', fontweight='bold')
ax.set_title('Compara√ß√£o: Modelos Base vs Otimizados', fontweight='bold', fontsize=14)
ax.set_xticks(x)
ax.set_xticklabels(comparison_df['Modelo'], rotation=45, ha='right')
ax.legend()
ax.set_ylim([0.85, 1.0])
ax.grid(True, alpha=0.3, axis='y')

# Adicionar valores nas barras
for bars in [bars1, bars2]:
    for bar in bars:
        height = bar.get_height()
        ax.text(bar.get_x() + bar.get_width()/2., height,
               f'{height:.3f}',
               ha='center', va='bottom', fontsize=8)

plt.tight_layout()
plt.show()
### 6.4 Matrizes de Confus√£o - Modelos Otimizados
# Matrizes de confus√£o dos modelos otimizados
fig, axes = plt.subplots(2, 3, figsize=(16, 10))
axes = axes.ravel()

for idx, (name, result) in enumerate(optimized_results.items()):
    cm = confusion_matrix(y_test, result['y_pred'])
    
    disp = ConfusionMatrixDisplay(
        confusion_matrix=cm,
        display_labels=['Kama', 'Rosa', 'Canadian']
    )
    
    disp.plot(ax=axes[idx], cmap='Greens', colorbar=False)
    axes[idx].set_title(f'{name} (Otimizado)\nAcur√°cia: {result["accuracy"]:.4f}',
                       fontweight='bold', fontsize=11)
    axes[idx].grid(False)

fig.delaxes(axes[5])

plt.tight_layout()
plt.suptitle('Matrizes de Confus√£o - Modelos Otimizados', fontsize=16, fontweight='bold', y=1.01)
plt.show()
## 7. An√°lise de Import√¢ncia das Features (Random Forest)
# Feature importance do Random Forest otimizado
rf_model = optimized_results['Random Forest']['model']
feature_importance = pd.DataFrame({
    'Feature': X.columns,
    'Import√¢ncia': rf_model.feature_importances_
}).sort_values('Import√¢ncia', ascending=False)

print("IMPORT√ÇNCIA DAS FEATURES (Random Forest Otimizado)")
print(f"{'='*60}")
print(feature_importance.to_string(index=False))
print(f"{'='*60}")

# Visualiza√ß√£o
plt.figure(figsize=(10, 6))
plt.barh(feature_importance['Feature'], feature_importance['Import√¢ncia'],
         color='forestgreen', alpha=0.7, edgecolor='black')
plt.xlabel('Import√¢ncia', fontweight='bold')
plt.ylabel('Feature', fontweight='bold')
plt.title('Import√¢ncia das Features - Random Forest', fontweight='bold', fontsize=14)
plt.gca().invert_yaxis()
plt.grid(True, alpha=0.3, axis='x')
plt.tight_layout()
plt.show()
## 8. Sele√ß√£o do Melhor Modelo
# Identificar o melhor modelo
best_model_name = comparison_df.iloc[0]['Modelo']
best_model_info = optimized_results[best_model_name]

print("MELHOR MODELO IDENTIFICADO")
print(f"{'='*60}")
print(f"Modelo: {best_model_name}")
print(f"Acur√°cia: {best_model_info['accuracy']:.4f}")
print(f"Precis√£o: {best_model_info['precision']:.4f}")
print(f"Recall: {best_model_info['recall']:.4f}")
print(f"F1-Score: {best_model_info['f1_score']:.4f}")
if best_model_info['best_params'] != 'N/A':
    print(f"\nMelhores Hiperpar√¢metros:")
    for param, value in best_model_info['best_params'].items():
        print(f"  ‚Ä¢ {param}: {value}")
print(f"{'='*60}")
## 9. Interpreta√ß√£o dos Resultados e Insights

### 9.1 An√°lise de Erros do Melhor Modelo
# An√°lise de erros
best_predictions = best_model_info['y_pred']
errors = y_test != best_predictions
error_indices = np.where(errors)[0]

print(f"AN√ÅLISE DE ERROS - {best_model_name}")
print(f"{'='*60}")
print(f"Total de erros: {errors.sum()} de {len(y_test)} ({errors.sum()/len(y_test)*100:.2f}%)")
print(f"\nDistribui√ß√£o dos erros:")

if errors.sum() > 0:
    error_df = pd.DataFrame({
        'Real': y_test.iloc[error_indices].map(variedades_map),
        'Predito': pd.Series(best_predictions[error_indices]).map(variedades_map)
    })
    print(error_df.groupby(['Real', 'Predito']).size().to_frame('Quantidade'))
else:
    print("Nenhum erro - Classifica√ß√£o perfeita!")
### 9.2 Resumo Executivo dos Resultados
print("\n" + "="*80)
print("RESUMO EXECUTIVO - CLASSIFICA√á√ÉO DE GR√ÉOS DE TRIGO")
print("="*80)

print("\n1. DATASET:")
print(f"   ‚Ä¢ Total de amostras: {len(df)}")
print(f"   ‚Ä¢ Features analisadas: {len(features)}")
print(f"   ‚Ä¢ Classes: 3 (Kama, Rosa, Canadian)")
print(f"   ‚Ä¢ Divis√£o: 70% treino / 30% teste")

print("\n2. MODELOS TESTADOS:")
for name in models.keys():
    print(f"   ‚Ä¢ {name}")

print("\n3. DESEMPENHO (Top 3 Modelos Otimizados):")
for idx, row in comparison_df.head(3).iterrows():
    print(f"   {idx+1}. {row['Modelo']}: {row['Acur√°cia Otimizada']:.4f} (melhoria: {row['Melhoria']:+.4f})")

print(f"\n4. MELHOR MODELO: {best_model_name}")
print(f"   ‚Ä¢ Acur√°cia: {best_model_info['accuracy']:.4f}")
print(f"   ‚Ä¢ F1-Score: {best_model_info['f1_score']:.4f}")
print(f"   ‚Ä¢ Taxa de erro: {(1-best_model_info['accuracy'])*100:.2f}%")

print("\n5. FEATURES MAIS IMPORTANTES (Random Forest):")
for idx, row in feature_importance.head(3).iterrows():
    print(f"   {idx+1}. {row['Feature']}: {row['Import√¢ncia']:.4f}")

print("\n6. PRINCIPAIS INSIGHTS:")
print("   ‚Ä¢ Dataset bem balanceado permite modelos robustos")
print("   ‚Ä¢ Alta correla√ß√£o entre Area e Perimetro (esperado geometricamente)")
print("   ‚Ä¢ Separabilidade clara entre variedades nas features morfol√≥gicas")
print("   ‚Ä¢ Otimiza√ß√£o de hiperpar√¢metros trouxe melhorias consistentes")
print(f"   ‚Ä¢ {best_model_name} apresenta melhor equil√≠brio precis√£o/generaliza√ß√£o")

print("\n7. APLICABILIDADE PR√ÅTICA:")
print("   ‚Ä¢ Modelo pronto para automa√ß√£o em cooperativas agr√≠colas")
print("   ‚Ä¢ Redu√ß√£o significativa de tempo vs classifica√ß√£o manual")
print("   ‚Ä¢ Minimiza√ß√£o de erros humanos no processo")
print("   ‚Ä¢ Possibilidade de integra√ß√£o com sistemas de vis√£o computacional")

print("\n" + "="*80)
## 10. Conclus√µes

### Principais Descobertas:

1. **Qualidade do Dataset**: O conjunto de dados Seeds apresenta excelente qualidade, com distribui√ß√£o balanceada entre as tr√™s variedades e aus√™ncia de valores faltantes.

2. **Separabilidade das Classes**: As caracter√≠sticas f√≠sicas dos gr√£os (especialmente √°rea, per√≠metro e compacidade) proporcionam boa separabilidade entre as variedades Kama, Rosa e Canadian.

3. **Desempenho dos Modelos**: Todos os algoritmos testados apresentaram desempenho superior a 90%, demonstrando que o problema √© bem adequado para t√©cnicas de aprendizado de m√°quina.

4. **Otimiza√ß√£o Efetiva**: A otimiza√ß√£o de hiperpar√¢metros via GridSearchCV resultou em melhorias consistentes, especialmente para KNN e SVM.

5. **Features Importantes**: As caracter√≠sticas geom√©tricas (√°rea, per√≠metro, compacidade) s√£o os principais discriminadores entre as variedades.

### Recomenda√ß√µes para Cooperativas Agr√≠colas:

1. **Implementa√ß√£o Gradual**: Iniciar com valida√ß√£o paralela (manual + autom√°tica) para ganhar confian√ßa no sistema.

2. **Coleta de Dados Cont√≠nua**: Manter registro das classifica√ß√µes para retreinamento peri√≥dico dos modelos.

3. **Integra√ß√£o com Vis√£o Computacional**: Combinar o modelo com sistemas de captura de imagem para automa√ß√£o completa.

4. **Monitoramento de Desempenho**: Estabelecer m√©tricas de acompanhamento para detectar degrada√ß√£o do modelo.

### Trabalhos Futuros:

1. Testar Deep Learning (CNNs) com imagens dos gr√£os
2. Expandir para outras variedades de trigo
3. Desenvolver interface web para uso pr√°tico
4. Estudar classifica√ß√£o em tempo real com edge computing
---

## Refer√™ncias

- UCI Machine Learning Repository: Seeds Dataset
- Scikit-learn Documentation
- CRISP-DM Methodology
